{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "NHGJpC0DNJTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "1IkyFe1MQ6jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ReLU, Dropout\n",
        "\n",
        "# Import and read in charity_data.csv\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")"
      ],
      "metadata": {
        "id": "W3eCfl1INKn1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-beneficial ID columns, 'EIN' and 'NAME'\n",
        "application_df.drop(columns=['EIN', 'NAME'], inplace=True)"
      ],
      "metadata": {
        "id": "UXAWFyKvN9a0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique values in each column\n",
        "for col in application_df.columns:\n",
        "  print(f\"{col}: {application_df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_INTGJRN-rd",
        "outputId": "46787d78-5ecb-488d-9b3a-72a372d4db95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPLICATION_TYPE: 17 unique values\n",
            "AFFILIATION: 6 unique values\n",
            "CLASSIFICATION: 71 unique values\n",
            "USE_CASE: 5 unique values\n",
            "ORGANIZATION: 4 unique values\n",
            "STATUS: 2 unique values\n",
            "INCOME_AMT: 9 unique values\n",
            "SPECIAL_CONSIDERATIONS: 2 unique values\n",
            "ASK_AMT: 8747 unique values\n",
            "IS_SUCCESSFUL: 2 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for APPLICATION_TYPE\n",
        "app_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "app_type_cutoff = 500\n",
        "application_types_to_replace = list(app_type_counts[app_type_counts < app_type_cutoff].index)\n",
        "\n",
        "for app in application_types_to_replace:\n",
        "  application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app, \"Other\")"
      ],
      "metadata": {
        "id": "SRRForsEOOAL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for CLASSIFICATION\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "class_cutoff = 1800\n",
        "classifications_to_replace = list(class_counts[class_counts < class_cutoff].index)\n",
        "\n",
        "for cls in classifications_to_replace:\n",
        "  application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls, \"Other\")"
      ],
      "metadata": {
        "id": "9WhuMHkHOujC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with 'pd.get_dummies'\n",
        "application_df = pd.get_dummies(application_df)"
      ],
      "metadata": {
        "id": "Ht3EvAB4PKNV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split preprocessed data into features and target arrays\n",
        "X = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# SPlit the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ],
      "metadata": {
        "id": "prHV7LeCPV_V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler isntance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gB0M34LEPvjw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation"
      ],
      "metadata": {
        "id": "JEByUluYQ-ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Design a neural network model with five hidden layers\n",
        "nn_optimized = tf.keras.models.Sequential()\n",
        "\n",
        "# First layer with Leaky ReLU activation\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=256, input_dim=len(X_train_scaled[0])))\n",
        "nn_optimized.add(LeakyReLU(alpha=0.1))\n",
        "nn_optimized.add(Dropout(0.3)) #Added dropout for regularization\n",
        "\n",
        "# Second layer with ReLU activation\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=128))\n",
        "nn_optimized.add(ReLU())\n",
        "nn_optimized.add(Dropout(0.3)) #Added dropout for regularization\n",
        "\n",
        "# Third layer with ELU activation\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=64))\n",
        "nn_optimized.add(ELU())\n",
        "nn_optimized.add(Dropout(0.3))  # Added dropout for regularization\n",
        "\n",
        "# Fourth layer with ReLU activation\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=32))\n",
        "nn_optimized.add(ReLU())\n",
        "nn_optimized.add(Dropout(0.3))  # Added dropout for regularization\n",
        "\n",
        "# Fifth layer with PReLU activation\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=16))\n",
        "nn_optimized.add(PReLU())\n",
        "nn_optimized.add(Dropout(0.3))  # Added dropout for regularization\n",
        "\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check structure of optimized model\n",
        "nn_optimized.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4XBcKrnQ5Vh",
        "outputId": "fa6e0fe5-0ccc-4c5f-e1e5-548701a3ef24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 256)               11264     \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " elu_2 (ELU)                 (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " p_re_lu_2 (PReLU)           (None, 16)                16        \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,057\n",
            "Trainable params: 55,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the optimized model\n",
        "nn_optimized.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "ZPDovICPVDkS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the optimized model with 200 epochs\n",
        "model_fit_optimized = nn_optimized.fit(X_train_scaled, y_train, epochs=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFbwRbdgVRAt",
        "outputId": "57cda312-ecb3-4f9c-9a78-6e1c1bd1f5ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "804/804 [==============================] - 5s 5ms/step - loss: 0.6064 - accuracy: 0.6971\n",
            "Epoch 2/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5783 - accuracy: 0.7234\n",
            "Epoch 3/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5716 - accuracy: 0.7277\n",
            "Epoch 4/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5677 - accuracy: 0.7286\n",
            "Epoch 5/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5689 - accuracy: 0.7288\n",
            "Epoch 6/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5657 - accuracy: 0.7302\n",
            "Epoch 7/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5631 - accuracy: 0.7308\n",
            "Epoch 8/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5641 - accuracy: 0.7300\n",
            "Epoch 9/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5623 - accuracy: 0.7292\n",
            "Epoch 10/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5618 - accuracy: 0.7305\n",
            "Epoch 11/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5591 - accuracy: 0.7322\n",
            "Epoch 12/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5610 - accuracy: 0.7325\n",
            "Epoch 13/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5586 - accuracy: 0.7324\n",
            "Epoch 14/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5594 - accuracy: 0.7324\n",
            "Epoch 15/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5580 - accuracy: 0.7329\n",
            "Epoch 16/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5590 - accuracy: 0.7321\n",
            "Epoch 17/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5577 - accuracy: 0.7313\n",
            "Epoch 18/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5571 - accuracy: 0.7331\n",
            "Epoch 19/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5561 - accuracy: 0.7326\n",
            "Epoch 20/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5564 - accuracy: 0.7311\n",
            "Epoch 21/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5566 - accuracy: 0.7329\n",
            "Epoch 22/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5564 - accuracy: 0.7328\n",
            "Epoch 23/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5542 - accuracy: 0.7346\n",
            "Epoch 24/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5551 - accuracy: 0.7330\n",
            "Epoch 25/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5554 - accuracy: 0.7325\n",
            "Epoch 26/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5558 - accuracy: 0.7363\n",
            "Epoch 27/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5539 - accuracy: 0.7334\n",
            "Epoch 28/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5541 - accuracy: 0.7333\n",
            "Epoch 29/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5553 - accuracy: 0.7325\n",
            "Epoch 30/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5563 - accuracy: 0.7330\n",
            "Epoch 31/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5537 - accuracy: 0.7348\n",
            "Epoch 32/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5538 - accuracy: 0.7319\n",
            "Epoch 33/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5532 - accuracy: 0.7357\n",
            "Epoch 34/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5527 - accuracy: 0.7344\n",
            "Epoch 35/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5534 - accuracy: 0.7339\n",
            "Epoch 36/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5520 - accuracy: 0.7350\n",
            "Epoch 37/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5544 - accuracy: 0.7342\n",
            "Epoch 38/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5533 - accuracy: 0.7364\n",
            "Epoch 39/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5534 - accuracy: 0.7333\n",
            "Epoch 40/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5537 - accuracy: 0.7339\n",
            "Epoch 41/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5514 - accuracy: 0.7367\n",
            "Epoch 42/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5531 - accuracy: 0.7348\n",
            "Epoch 43/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5520 - accuracy: 0.7344\n",
            "Epoch 44/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5522 - accuracy: 0.7335\n",
            "Epoch 45/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5536 - accuracy: 0.7339\n",
            "Epoch 46/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7383\n",
            "Epoch 47/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7351\n",
            "Epoch 48/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5509 - accuracy: 0.7345\n",
            "Epoch 49/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5534 - accuracy: 0.7339\n",
            "Epoch 50/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5528 - accuracy: 0.7329\n",
            "Epoch 51/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5520 - accuracy: 0.7333\n",
            "Epoch 52/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5524 - accuracy: 0.7359\n",
            "Epoch 53/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5516 - accuracy: 0.7343\n",
            "Epoch 54/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5511 - accuracy: 0.7356\n",
            "Epoch 55/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7344\n",
            "Epoch 56/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7337\n",
            "Epoch 57/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5507 - accuracy: 0.7348\n",
            "Epoch 58/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5516 - accuracy: 0.7349\n",
            "Epoch 59/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7348\n",
            "Epoch 60/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5501 - accuracy: 0.7362\n",
            "Epoch 61/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5504 - accuracy: 0.7359\n",
            "Epoch 62/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5519 - accuracy: 0.7364\n",
            "Epoch 63/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5504 - accuracy: 0.7357\n",
            "Epoch 64/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5516 - accuracy: 0.7345\n",
            "Epoch 65/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5511 - accuracy: 0.7355\n",
            "Epoch 66/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5514 - accuracy: 0.7339\n",
            "Epoch 67/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5507 - accuracy: 0.7346\n",
            "Epoch 68/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5494 - accuracy: 0.7360\n",
            "Epoch 69/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5511 - accuracy: 0.7348\n",
            "Epoch 70/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5500 - accuracy: 0.7358\n",
            "Epoch 71/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5510 - accuracy: 0.7341\n",
            "Epoch 72/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5501 - accuracy: 0.7338\n",
            "Epoch 73/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7354\n",
            "Epoch 74/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5517 - accuracy: 0.7358\n",
            "Epoch 75/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5501 - accuracy: 0.7343\n",
            "Epoch 76/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5518 - accuracy: 0.7335\n",
            "Epoch 77/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5500 - accuracy: 0.7341\n",
            "Epoch 78/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5518 - accuracy: 0.7344\n",
            "Epoch 79/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5509 - accuracy: 0.7334\n",
            "Epoch 80/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5501 - accuracy: 0.7329\n",
            "Epoch 81/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5503 - accuracy: 0.7354\n",
            "Epoch 82/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7347\n",
            "Epoch 83/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5488 - accuracy: 0.7363\n",
            "Epoch 84/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5491 - accuracy: 0.7340\n",
            "Epoch 85/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5491 - accuracy: 0.7350\n",
            "Epoch 86/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5499 - accuracy: 0.7349\n",
            "Epoch 87/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7350\n",
            "Epoch 88/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5493 - accuracy: 0.7346\n",
            "Epoch 89/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5495 - accuracy: 0.7341\n",
            "Epoch 90/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5485 - accuracy: 0.7360\n",
            "Epoch 91/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5508 - accuracy: 0.7346\n",
            "Epoch 92/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5519 - accuracy: 0.7353\n",
            "Epoch 93/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5507 - accuracy: 0.7356\n",
            "Epoch 94/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5505 - accuracy: 0.7363\n",
            "Epoch 95/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5516 - accuracy: 0.7350\n",
            "Epoch 96/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5501 - accuracy: 0.7341\n",
            "Epoch 97/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7357\n",
            "Epoch 98/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5486 - accuracy: 0.7365\n",
            "Epoch 99/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5497 - accuracy: 0.7367\n",
            "Epoch 100/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5517 - accuracy: 0.7351\n",
            "Epoch 101/200\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.5498 - accuracy: 0.7357\n",
            "Epoch 102/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7356\n",
            "Epoch 103/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5501 - accuracy: 0.7365\n",
            "Epoch 104/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5492 - accuracy: 0.7349\n",
            "Epoch 105/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5493 - accuracy: 0.7353\n",
            "Epoch 106/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7350\n",
            "Epoch 107/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7362\n",
            "Epoch 108/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5493 - accuracy: 0.7369\n",
            "Epoch 109/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5500 - accuracy: 0.7362\n",
            "Epoch 110/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5511 - accuracy: 0.7339\n",
            "Epoch 111/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7356\n",
            "Epoch 112/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5491 - accuracy: 0.7351\n",
            "Epoch 113/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7355\n",
            "Epoch 114/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7345\n",
            "Epoch 115/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5486 - accuracy: 0.7364\n",
            "Epoch 116/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5483 - accuracy: 0.7363\n",
            "Epoch 117/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7352\n",
            "Epoch 118/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7372\n",
            "Epoch 119/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5492 - accuracy: 0.7366\n",
            "Epoch 120/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5492 - accuracy: 0.7360\n",
            "Epoch 121/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5491 - accuracy: 0.7353\n",
            "Epoch 122/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5492 - accuracy: 0.7345\n",
            "Epoch 123/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7347\n",
            "Epoch 124/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5482 - accuracy: 0.7355\n",
            "Epoch 125/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7361\n",
            "Epoch 126/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5498 - accuracy: 0.7361\n",
            "Epoch 127/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5506 - accuracy: 0.7347\n",
            "Epoch 128/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5504 - accuracy: 0.7350\n",
            "Epoch 129/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5483 - accuracy: 0.7372\n",
            "Epoch 130/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5483 - accuracy: 0.7362\n",
            "Epoch 131/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5477 - accuracy: 0.7368\n",
            "Epoch 132/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5503 - accuracy: 0.7370\n",
            "Epoch 133/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5481 - accuracy: 0.7362\n",
            "Epoch 134/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7365\n",
            "Epoch 135/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5514 - accuracy: 0.7352\n",
            "Epoch 136/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.7379\n",
            "Epoch 137/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5486 - accuracy: 0.7379\n",
            "Epoch 138/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7383\n",
            "Epoch 139/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5505 - accuracy: 0.7347\n",
            "Epoch 140/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7348\n",
            "Epoch 141/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7376\n",
            "Epoch 142/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5489 - accuracy: 0.7375\n",
            "Epoch 143/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5477 - accuracy: 0.7372\n",
            "Epoch 144/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5489 - accuracy: 0.7363\n",
            "Epoch 145/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5495 - accuracy: 0.7361\n",
            "Epoch 146/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5479 - accuracy: 0.7360\n",
            "Epoch 147/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7358\n",
            "Epoch 148/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5473 - accuracy: 0.7376\n",
            "Epoch 149/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7365\n",
            "Epoch 150/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5497 - accuracy: 0.7352\n",
            "Epoch 151/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5467 - accuracy: 0.7384\n",
            "Epoch 152/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7361\n",
            "Epoch 153/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5479 - accuracy: 0.7367\n",
            "Epoch 154/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5489 - accuracy: 0.7370\n",
            "Epoch 155/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5488 - accuracy: 0.7355\n",
            "Epoch 156/200\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5482 - accuracy: 0.7361\n",
            "Epoch 157/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5472 - accuracy: 0.7371\n",
            "Epoch 158/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5486 - accuracy: 0.7376\n",
            "Epoch 159/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7361\n",
            "Epoch 160/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7364\n",
            "Epoch 161/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5475 - accuracy: 0.7378\n",
            "Epoch 162/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5491 - accuracy: 0.7379\n",
            "Epoch 163/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5476 - accuracy: 0.7376\n",
            "Epoch 164/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7364\n",
            "Epoch 165/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5486 - accuracy: 0.7376\n",
            "Epoch 166/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7372\n",
            "Epoch 167/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5476 - accuracy: 0.7359\n",
            "Epoch 168/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5489 - accuracy: 0.7364\n",
            "Epoch 169/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5484 - accuracy: 0.7372\n",
            "Epoch 170/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5481 - accuracy: 0.7371\n",
            "Epoch 171/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7365\n",
            "Epoch 172/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5483 - accuracy: 0.7373\n",
            "Epoch 173/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5492 - accuracy: 0.7365\n",
            "Epoch 174/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5505 - accuracy: 0.7353\n",
            "Epoch 175/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.7377\n",
            "Epoch 176/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5482 - accuracy: 0.7365\n",
            "Epoch 177/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7366\n",
            "Epoch 178/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5472 - accuracy: 0.7357\n",
            "Epoch 179/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5488 - accuracy: 0.7369\n",
            "Epoch 180/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5477 - accuracy: 0.7365\n",
            "Epoch 181/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7372\n",
            "Epoch 182/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5483 - accuracy: 0.7370\n",
            "Epoch 183/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.7373\n",
            "Epoch 184/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5477 - accuracy: 0.7375\n",
            "Epoch 185/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7390\n",
            "Epoch 186/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5479 - accuracy: 0.7364\n",
            "Epoch 187/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7369\n",
            "Epoch 188/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5475 - accuracy: 0.7357\n",
            "Epoch 189/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5495 - accuracy: 0.7378\n",
            "Epoch 190/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5457 - accuracy: 0.7386\n",
            "Epoch 191/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5471 - accuracy: 0.7375\n",
            "Epoch 192/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5496 - accuracy: 0.7355\n",
            "Epoch 193/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5483 - accuracy: 0.7387\n",
            "Epoch 194/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5488 - accuracy: 0.7372\n",
            "Epoch 195/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7374\n",
            "Epoch 196/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5482 - accuracy: 0.7387\n",
            "Epoch 197/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5512 - accuracy: 0.7377\n",
            "Epoch 198/200\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5484 - accuracy: 0.7372\n",
            "Epoch 199/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7371\n",
            "Epoch 200/200\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5484 - accuracy: 0.7364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the optimized model using the test data\n",
        "model_loss_optimized, model_accuracy_optimized = nn_optimized.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Model Loss: {model_loss_optimized}, Optimized Model Accuracy: {model_accuracy_optimized}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3VCf-nQX8ze",
        "outputId": "273586fe-e316-4bf1-d531-48a9ab5bdfdc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5587 - accuracy: 0.7257 - 559ms/epoch - 2ms/step\n",
            "Optimized Model Loss: 0.5586734414100647, Optimized Model Accuracy: 0.7257142663002014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further Optimization and another Model"
      ],
      "metadata": {
        "id": "ToVEeNKVdcTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Optimization\n",
        "\n",
        "# Design a neural network model with more hidden layers and different activation functions\n",
        "nn_optimized_2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First layer with Leaky ReLU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=256, input_dim=len(X_train_scaled[0])))\n",
        "nn_optimized_2.add(LeakyReLU(alpha=0.1))\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Second layer with ReLU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=128))\n",
        "nn_optimized_2.add(ReLU())\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Third layer with ELU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=64))\n",
        "nn_optimized_2.add(ELU())\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Fourth layer with SELU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=32))\n",
        "nn_optimized_2.add(tf.keras.layers.Activation('selu'))\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Fifth layer with Swish activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=16))\n",
        "nn_optimized_2.add(tf.keras.layers.Activation('swish'))\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Sixth layer with PReLU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=8))\n",
        "nn_optimized_2.add(PReLU())\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Seventh layer with ReLU activation\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=4))\n",
        "nn_optimized_2.add(ReLU())\n",
        "nn_optimized_2.add(Dropout(0.4))  # Adding dropout for regularization\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "nn_optimized_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the optimized model\n",
        "nn_optimized_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niBvp3YJdkCj",
        "outputId": "326f17ae-a308-4624-e35b-714e2ca632a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 256)               11264     \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " elu_3 (ELU)                 (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " p_re_lu_3 (PReLU)           (None, 8)                 8         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 4)                 0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,209\n",
            "Trainable params: 55,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the optimized model\n",
        "nn_optimized_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "LhZkqUo6du3k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the optimized model with 300 epochs\n",
        "model_fit_optimized_2 = nn_optimized_2.fit(X_train_scaled, y_train, epochs=300)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJjcKD1Pdyhi",
        "outputId": "0d4dd95e-e573-4b52-b0c0-88259372c649"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "804/804 [==============================] - 6s 5ms/step - loss: 0.6867 - accuracy: 0.5639\n",
            "Epoch 2/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6485 - accuracy: 0.6297\n",
            "Epoch 3/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6287 - accuracy: 0.6677\n",
            "Epoch 4/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.6160 - accuracy: 0.6820\n",
            "Epoch 5/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.6180 - accuracy: 0.6828\n",
            "Epoch 6/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.6096 - accuracy: 0.6937\n",
            "Epoch 7/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.6054 - accuracy: 0.7001\n",
            "Epoch 8/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.6079 - accuracy: 0.6954\n",
            "Epoch 9/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6019 - accuracy: 0.6982\n",
            "Epoch 10/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6013 - accuracy: 0.7017\n",
            "Epoch 11/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5963 - accuracy: 0.7049\n",
            "Epoch 12/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5945 - accuracy: 0.7091\n",
            "Epoch 13/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5974 - accuracy: 0.7037\n",
            "Epoch 14/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5946 - accuracy: 0.7042\n",
            "Epoch 15/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5953 - accuracy: 0.7035\n",
            "Epoch 16/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5988 - accuracy: 0.7024\n",
            "Epoch 17/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5952 - accuracy: 0.7072\n",
            "Epoch 18/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5952 - accuracy: 0.7065\n",
            "Epoch 19/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5943 - accuracy: 0.7055\n",
            "Epoch 20/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5952 - accuracy: 0.7073\n",
            "Epoch 21/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5921 - accuracy: 0.7078\n",
            "Epoch 22/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5921 - accuracy: 0.7027\n",
            "Epoch 23/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5922 - accuracy: 0.7056\n",
            "Epoch 24/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5929 - accuracy: 0.7050\n",
            "Epoch 25/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5918 - accuracy: 0.7098\n",
            "Epoch 26/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5922 - accuracy: 0.7048\n",
            "Epoch 27/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5918 - accuracy: 0.7072\n",
            "Epoch 28/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5929 - accuracy: 0.7090\n",
            "Epoch 29/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5919 - accuracy: 0.7094\n",
            "Epoch 30/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5920 - accuracy: 0.7084\n",
            "Epoch 31/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5912 - accuracy: 0.7093\n",
            "Epoch 32/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5910 - accuracy: 0.7079\n",
            "Epoch 33/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5910 - accuracy: 0.7086\n",
            "Epoch 34/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5893 - accuracy: 0.7096\n",
            "Epoch 35/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5910 - accuracy: 0.7129\n",
            "Epoch 36/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5906 - accuracy: 0.7122\n",
            "Epoch 37/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7104\n",
            "Epoch 38/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5922 - accuracy: 0.7075\n",
            "Epoch 39/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5914 - accuracy: 0.7076\n",
            "Epoch 40/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5913 - accuracy: 0.7067\n",
            "Epoch 41/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5910 - accuracy: 0.7055\n",
            "Epoch 42/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5908 - accuracy: 0.7064\n",
            "Epoch 43/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5902 - accuracy: 0.7084\n",
            "Epoch 44/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5899 - accuracy: 0.7061\n",
            "Epoch 45/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5893 - accuracy: 0.7088\n",
            "Epoch 46/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5885 - accuracy: 0.7107\n",
            "Epoch 47/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5906 - accuracy: 0.7074\n",
            "Epoch 48/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5901 - accuracy: 0.7083\n",
            "Epoch 49/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5906 - accuracy: 0.7043\n",
            "Epoch 50/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5868 - accuracy: 0.7114\n",
            "Epoch 51/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5902 - accuracy: 0.7122\n",
            "Epoch 52/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5885 - accuracy: 0.7079\n",
            "Epoch 53/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5872 - accuracy: 0.7121\n",
            "Epoch 54/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5914 - accuracy: 0.7065\n",
            "Epoch 55/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5893 - accuracy: 0.7127\n",
            "Epoch 56/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5862 - accuracy: 0.7123\n",
            "Epoch 57/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5912 - accuracy: 0.7090\n",
            "Epoch 58/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5873 - accuracy: 0.7155\n",
            "Epoch 59/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5917 - accuracy: 0.7100\n",
            "Epoch 60/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5904 - accuracy: 0.7124\n",
            "Epoch 61/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5892 - accuracy: 0.7115\n",
            "Epoch 62/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5892 - accuracy: 0.7112\n",
            "Epoch 63/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5874 - accuracy: 0.7164\n",
            "Epoch 64/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5897 - accuracy: 0.7119\n",
            "Epoch 65/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5901 - accuracy: 0.7127\n",
            "Epoch 66/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5895 - accuracy: 0.7088\n",
            "Epoch 67/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5896 - accuracy: 0.7103\n",
            "Epoch 68/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5903 - accuracy: 0.7112\n",
            "Epoch 69/300\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.5903 - accuracy: 0.7103\n",
            "Epoch 70/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5875 - accuracy: 0.7108\n",
            "Epoch 71/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5896 - accuracy: 0.7130\n",
            "Epoch 72/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5872 - accuracy: 0.7125\n",
            "Epoch 73/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5868 - accuracy: 0.7137\n",
            "Epoch 74/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5897 - accuracy: 0.7141\n",
            "Epoch 75/300\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.5871 - accuracy: 0.7163\n",
            "Epoch 76/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5888 - accuracy: 0.7140\n",
            "Epoch 77/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5901 - accuracy: 0.7118\n",
            "Epoch 78/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5876 - accuracy: 0.7152\n",
            "Epoch 79/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5871 - accuracy: 0.7136\n",
            "Epoch 80/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5849 - accuracy: 0.7168\n",
            "Epoch 81/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5870 - accuracy: 0.7145\n",
            "Epoch 82/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7093\n",
            "Epoch 83/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5875 - accuracy: 0.7128\n",
            "Epoch 84/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5883 - accuracy: 0.7165\n",
            "Epoch 85/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5879 - accuracy: 0.7118\n",
            "Epoch 86/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5861 - accuracy: 0.7147\n",
            "Epoch 87/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7130\n",
            "Epoch 88/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5848 - accuracy: 0.7184\n",
            "Epoch 89/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5892 - accuracy: 0.7135\n",
            "Epoch 90/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5871 - accuracy: 0.7166\n",
            "Epoch 91/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5869 - accuracy: 0.7168\n",
            "Epoch 92/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7154\n",
            "Epoch 93/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5880 - accuracy: 0.7162\n",
            "Epoch 94/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5855 - accuracy: 0.7153\n",
            "Epoch 95/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5875 - accuracy: 0.7175\n",
            "Epoch 96/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7150\n",
            "Epoch 97/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5873 - accuracy: 0.7125\n",
            "Epoch 98/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5873 - accuracy: 0.7107\n",
            "Epoch 99/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.7118\n",
            "Epoch 100/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5891 - accuracy: 0.7149\n",
            "Epoch 101/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5874 - accuracy: 0.7125\n",
            "Epoch 102/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5862 - accuracy: 0.7119\n",
            "Epoch 103/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5865 - accuracy: 0.7125\n",
            "Epoch 104/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5844 - accuracy: 0.7158\n",
            "Epoch 105/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5884 - accuracy: 0.7149\n",
            "Epoch 106/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5880 - accuracy: 0.7140\n",
            "Epoch 107/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7139\n",
            "Epoch 108/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5881 - accuracy: 0.7135\n",
            "Epoch 109/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5866 - accuracy: 0.7144\n",
            "Epoch 110/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5869 - accuracy: 0.7161\n",
            "Epoch 111/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5881 - accuracy: 0.7128\n",
            "Epoch 112/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5859 - accuracy: 0.7188\n",
            "Epoch 113/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5870 - accuracy: 0.7156\n",
            "Epoch 114/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5907 - accuracy: 0.7098\n",
            "Epoch 115/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5856 - accuracy: 0.7156\n",
            "Epoch 116/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5871 - accuracy: 0.7159\n",
            "Epoch 117/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5856 - accuracy: 0.7130\n",
            "Epoch 118/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5872 - accuracy: 0.7114\n",
            "Epoch 119/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5903 - accuracy: 0.7131\n",
            "Epoch 120/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5870 - accuracy: 0.7127\n",
            "Epoch 121/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5872 - accuracy: 0.7116\n",
            "Epoch 122/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5865 - accuracy: 0.7100\n",
            "Epoch 123/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5848 - accuracy: 0.7128\n",
            "Epoch 124/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.7110\n",
            "Epoch 125/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5885 - accuracy: 0.7124\n",
            "Epoch 126/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5886 - accuracy: 0.7154\n",
            "Epoch 127/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5868 - accuracy: 0.7126\n",
            "Epoch 128/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5844 - accuracy: 0.7134\n",
            "Epoch 129/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5846 - accuracy: 0.7155\n",
            "Epoch 130/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5842 - accuracy: 0.7149\n",
            "Epoch 131/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5865 - accuracy: 0.7136\n",
            "Epoch 132/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5857 - accuracy: 0.7151\n",
            "Epoch 133/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5846 - accuracy: 0.7151\n",
            "Epoch 134/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5872 - accuracy: 0.7115\n",
            "Epoch 135/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5860 - accuracy: 0.7116\n",
            "Epoch 136/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5863 - accuracy: 0.7139\n",
            "Epoch 137/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7151\n",
            "Epoch 138/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5856 - accuracy: 0.7154\n",
            "Epoch 139/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5842 - accuracy: 0.7140\n",
            "Epoch 140/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5854 - accuracy: 0.7144\n",
            "Epoch 141/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5877 - accuracy: 0.7119\n",
            "Epoch 142/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5873 - accuracy: 0.7086\n",
            "Epoch 143/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5885 - accuracy: 0.7146\n",
            "Epoch 144/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5879 - accuracy: 0.7136\n",
            "Epoch 145/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5830 - accuracy: 0.7177\n",
            "Epoch 146/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5887 - accuracy: 0.7131\n",
            "Epoch 147/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5889 - accuracy: 0.7117\n",
            "Epoch 148/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5855 - accuracy: 0.7167\n",
            "Epoch 149/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5854 - accuracy: 0.7141\n",
            "Epoch 150/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5875 - accuracy: 0.7138\n",
            "Epoch 151/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5853 - accuracy: 0.7135\n",
            "Epoch 152/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5840 - accuracy: 0.7166\n",
            "Epoch 153/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5844 - accuracy: 0.7133\n",
            "Epoch 154/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5841 - accuracy: 0.7170\n",
            "Epoch 155/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5856 - accuracy: 0.7129\n",
            "Epoch 156/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5879 - accuracy: 0.7149\n",
            "Epoch 157/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5869 - accuracy: 0.7127\n",
            "Epoch 158/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5885 - accuracy: 0.7131\n",
            "Epoch 159/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5865 - accuracy: 0.7123\n",
            "Epoch 160/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5909 - accuracy: 0.7072\n",
            "Epoch 161/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7137\n",
            "Epoch 162/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5864 - accuracy: 0.7149\n",
            "Epoch 163/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5878 - accuracy: 0.7121\n",
            "Epoch 164/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5856 - accuracy: 0.7130\n",
            "Epoch 165/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5882 - accuracy: 0.7144\n",
            "Epoch 166/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.7119\n",
            "Epoch 167/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5826 - accuracy: 0.7162\n",
            "Epoch 168/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5867 - accuracy: 0.7140\n",
            "Epoch 169/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5836 - accuracy: 0.7165\n",
            "Epoch 170/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5877 - accuracy: 0.7114\n",
            "Epoch 171/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5874 - accuracy: 0.7140\n",
            "Epoch 172/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5843 - accuracy: 0.7137\n",
            "Epoch 173/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5863 - accuracy: 0.7110\n",
            "Epoch 174/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5861 - accuracy: 0.7140\n",
            "Epoch 175/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5861 - accuracy: 0.7109\n",
            "Epoch 176/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7110\n",
            "Epoch 177/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5891 - accuracy: 0.7110\n",
            "Epoch 178/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5875 - accuracy: 0.7124\n",
            "Epoch 179/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5876 - accuracy: 0.7131\n",
            "Epoch 180/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5880 - accuracy: 0.7144\n",
            "Epoch 181/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7160\n",
            "Epoch 182/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5870 - accuracy: 0.7131\n",
            "Epoch 183/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5886 - accuracy: 0.7123\n",
            "Epoch 184/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5885 - accuracy: 0.7140\n",
            "Epoch 185/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5837 - accuracy: 0.7169\n",
            "Epoch 186/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5872 - accuracy: 0.7135\n",
            "Epoch 187/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5870 - accuracy: 0.7108\n",
            "Epoch 188/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.7151\n",
            "Epoch 189/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5841 - accuracy: 0.7134\n",
            "Epoch 190/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5871 - accuracy: 0.7119\n",
            "Epoch 191/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5873 - accuracy: 0.7117\n",
            "Epoch 192/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5869 - accuracy: 0.7140\n",
            "Epoch 193/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5867 - accuracy: 0.7124\n",
            "Epoch 194/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5890 - accuracy: 0.7135\n",
            "Epoch 195/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7133\n",
            "Epoch 196/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5827 - accuracy: 0.7136\n",
            "Epoch 197/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5877 - accuracy: 0.7131\n",
            "Epoch 198/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5850 - accuracy: 0.7130\n",
            "Epoch 199/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5897 - accuracy: 0.7127\n",
            "Epoch 200/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5862 - accuracy: 0.7134\n",
            "Epoch 201/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5841 - accuracy: 0.7165\n",
            "Epoch 202/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5893 - accuracy: 0.7109\n",
            "Epoch 203/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5864 - accuracy: 0.7104\n",
            "Epoch 204/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5870 - accuracy: 0.7141\n",
            "Epoch 205/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5867 - accuracy: 0.7126\n",
            "Epoch 206/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5844 - accuracy: 0.7140\n",
            "Epoch 207/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5868 - accuracy: 0.7126\n",
            "Epoch 208/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5842 - accuracy: 0.7137\n",
            "Epoch 209/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5864 - accuracy: 0.7144\n",
            "Epoch 210/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5880 - accuracy: 0.7128\n",
            "Epoch 211/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5849 - accuracy: 0.7155\n",
            "Epoch 212/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5863 - accuracy: 0.7143\n",
            "Epoch 213/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5852 - accuracy: 0.7169\n",
            "Epoch 214/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5907 - accuracy: 0.7156\n",
            "Epoch 215/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5911 - accuracy: 0.7144\n",
            "Epoch 216/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5870 - accuracy: 0.7145\n",
            "Epoch 217/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5852 - accuracy: 0.7151\n",
            "Epoch 218/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7160\n",
            "Epoch 219/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5875 - accuracy: 0.7155\n",
            "Epoch 220/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5829 - accuracy: 0.7132\n",
            "Epoch 221/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5888 - accuracy: 0.7122\n",
            "Epoch 222/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5856 - accuracy: 0.7190\n",
            "Epoch 223/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5866 - accuracy: 0.7166\n",
            "Epoch 224/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5887 - accuracy: 0.7149\n",
            "Epoch 225/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5880 - accuracy: 0.7137\n",
            "Epoch 226/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5872 - accuracy: 0.7171\n",
            "Epoch 227/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5889 - accuracy: 0.7144\n",
            "Epoch 228/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5869 - accuracy: 0.7146\n",
            "Epoch 229/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5877 - accuracy: 0.7152\n",
            "Epoch 230/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5873 - accuracy: 0.7154\n",
            "Epoch 231/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5874 - accuracy: 0.7108\n",
            "Epoch 232/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5863 - accuracy: 0.7210\n",
            "Epoch 233/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5865 - accuracy: 0.7159\n",
            "Epoch 234/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5862 - accuracy: 0.7151\n",
            "Epoch 235/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.7136\n",
            "Epoch 236/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5863 - accuracy: 0.7169\n",
            "Epoch 237/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5889 - accuracy: 0.7149\n",
            "Epoch 238/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5856 - accuracy: 0.7170\n",
            "Epoch 239/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5856 - accuracy: 0.7107\n",
            "Epoch 240/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5846 - accuracy: 0.7159\n",
            "Epoch 241/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5863 - accuracy: 0.7146\n",
            "Epoch 242/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5858 - accuracy: 0.7140\n",
            "Epoch 243/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5868 - accuracy: 0.7148\n",
            "Epoch 244/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5855 - accuracy: 0.7131\n",
            "Epoch 245/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5869 - accuracy: 0.7131\n",
            "Epoch 246/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5832 - accuracy: 0.7185\n",
            "Epoch 247/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5853 - accuracy: 0.7168\n",
            "Epoch 248/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5907 - accuracy: 0.7160\n",
            "Epoch 249/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5888 - accuracy: 0.7139\n",
            "Epoch 250/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5865 - accuracy: 0.7119\n",
            "Epoch 251/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5874 - accuracy: 0.7137\n",
            "Epoch 252/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5841 - accuracy: 0.7158\n",
            "Epoch 253/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5857 - accuracy: 0.7177\n",
            "Epoch 254/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5871 - accuracy: 0.7133\n",
            "Epoch 255/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5848 - accuracy: 0.7150\n",
            "Epoch 256/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5858 - accuracy: 0.7135\n",
            "Epoch 257/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5845 - accuracy: 0.7163\n",
            "Epoch 258/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5858 - accuracy: 0.7117\n",
            "Epoch 259/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5878 - accuracy: 0.7139\n",
            "Epoch 260/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5867 - accuracy: 0.7124\n",
            "Epoch 261/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5842 - accuracy: 0.7147\n",
            "Epoch 262/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5853 - accuracy: 0.7124\n",
            "Epoch 263/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5877 - accuracy: 0.7133\n",
            "Epoch 264/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5873 - accuracy: 0.7145\n",
            "Epoch 265/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5851 - accuracy: 0.7145\n",
            "Epoch 266/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5878 - accuracy: 0.7143\n",
            "Epoch 267/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5861 - accuracy: 0.7098\n",
            "Epoch 268/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5850 - accuracy: 0.7138\n",
            "Epoch 269/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5866 - accuracy: 0.7116\n",
            "Epoch 270/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5840 - accuracy: 0.7129\n",
            "Epoch 271/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5875 - accuracy: 0.7105\n",
            "Epoch 272/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5846 - accuracy: 0.7129\n",
            "Epoch 273/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5839 - accuracy: 0.7133\n",
            "Epoch 274/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5851 - accuracy: 0.7144\n",
            "Epoch 275/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5836 - accuracy: 0.7155\n",
            "Epoch 276/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5869 - accuracy: 0.7112\n",
            "Epoch 277/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5835 - accuracy: 0.7153\n",
            "Epoch 278/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5838 - accuracy: 0.7132\n",
            "Epoch 279/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5840 - accuracy: 0.7108\n",
            "Epoch 280/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5870 - accuracy: 0.7131\n",
            "Epoch 281/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5852 - accuracy: 0.7140\n",
            "Epoch 282/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5867 - accuracy: 0.7111\n",
            "Epoch 283/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5853 - accuracy: 0.7143\n",
            "Epoch 284/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5869 - accuracy: 0.7114\n",
            "Epoch 285/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5847 - accuracy: 0.7138\n",
            "Epoch 286/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5873 - accuracy: 0.7099\n",
            "Epoch 287/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5878 - accuracy: 0.7124\n",
            "Epoch 288/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5852 - accuracy: 0.7135\n",
            "Epoch 289/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5880 - accuracy: 0.7110\n",
            "Epoch 290/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5846 - accuracy: 0.7153\n",
            "Epoch 291/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5860 - accuracy: 0.7137\n",
            "Epoch 292/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5860 - accuracy: 0.7154\n",
            "Epoch 293/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5898 - accuracy: 0.7102\n",
            "Epoch 294/300\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5861 - accuracy: 0.7130\n",
            "Epoch 295/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5893 - accuracy: 0.7116\n",
            "Epoch 296/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5902 - accuracy: 0.7144\n",
            "Epoch 297/300\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5863 - accuracy: 0.7140\n",
            "Epoch 298/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5851 - accuracy: 0.7111\n",
            "Epoch 299/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5875 - accuracy: 0.7121\n",
            "Epoch 300/300\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5908 - accuracy: 0.7126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the optimized model using the test data\n",
        "model_loss_optimized_2, model_accuracy_optimized_2 = nn_optimized_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Model Loss: {model_loss_optimized_2}, Optimized Model Accuracy: {model_accuracy_optimized_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKUEOVDd2IB",
        "outputId": "65b49827-49de-42d3-cb85-8c2841e91675"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5598 - accuracy: 0.7264 - 592ms/epoch - 2ms/step\n",
            "Optimized Model Loss: 0.5597774982452393, Optimized Model Accuracy: 0.7264139652252197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third Optimization\n",
        "\n",
        "# Design a neural network model with more hidden layers and different activation functions\n",
        "nn_optimized_3 = tf.keras.models.Sequential()\n",
        "\n",
        "# First layer with Leaky ReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=512, input_dim=len(X_train_scaled[0])))\n",
        "nn_optimized_3.add(LeakyReLU(alpha=0.2))\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Second layer with ReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=256))\n",
        "nn_optimized_3.add(ReLU())\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Third layer with SELU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=128))\n",
        "nn_optimized_3.add(tf.keras.layers.Activation('selu'))\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Fourth layer with Swish activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=64))\n",
        "nn_optimized_3.add(tf.keras.layers.Activation('swish'))\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Fifth layer with PReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=32))\n",
        "nn_optimized_3.add(PReLU())\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Sixth layer with ELU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=16))\n",
        "nn_optimized_3.add(ELU())\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Seventh layer with Swish activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=8))\n",
        "nn_optimized_3.add(tf.keras.layers.Activation('swish'))\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Eighth layer with Leaky ReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=4))\n",
        "nn_optimized_3.add(LeakyReLU(alpha=0.2))\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Ninth layer with ReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=2))\n",
        "nn_optimized_3.add(ReLU())\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Tenth layer with PReLU activation\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=1))\n",
        "nn_optimized_3.add(PReLU())\n",
        "nn_optimized_3.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "nn_optimized_3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the optimized model\n",
        "nn_optimized_3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDYJnsStjBNY",
        "outputId": "f3059326-e54b-4347-d6dd-e58fcf7d3c69"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_47 (Dense)            (None, 512)               22528     \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " p_re_lu_7 (PReLU)           (None, 32)                32        \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " elu_6 (ELU)                 (None, 16)                0         \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 4)                 0         \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 2)                 0         \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            " p_re_lu_8 (PReLU)           (None, 1)                 1         \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 1)                 0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 197,836\n",
            "Trainable params: 197,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the optimized model\n",
        "nn_optimized_3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "mawOhbM-jd6X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the optimized model with 500 epochs\n",
        "model_fit_optimized_3 = nn_optimized_3.fit(X_train_scaled, y_train, epochs=500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObpBwBuOjfv0",
        "outputId": "f5684366-fa00-49fe-bfcb-39408b0236fc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6293 - accuracy: 0.6498\n",
            "Epoch 2/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6489\n",
            "Epoch 3/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6309 - accuracy: 0.6484\n",
            "Epoch 4/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6333 - accuracy: 0.6488\n",
            "Epoch 5/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6454\n",
            "Epoch 6/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6306 - accuracy: 0.6497\n",
            "Epoch 7/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6330 - accuracy: 0.6473\n",
            "Epoch 8/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6281 - accuracy: 0.6546\n",
            "Epoch 9/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6302 - accuracy: 0.6466\n",
            "Epoch 10/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6352 - accuracy: 0.6442\n",
            "Epoch 11/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6348 - accuracy: 0.6426\n",
            "Epoch 12/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6354 - accuracy: 0.6396\n",
            "Epoch 13/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6333 - accuracy: 0.6490\n",
            "Epoch 14/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6343 - accuracy: 0.6482\n",
            "Epoch 15/500\n",
            "804/804 [==============================] - 10s 12ms/step - loss: 0.6334 - accuracy: 0.6474\n",
            "Epoch 16/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6308 - accuracy: 0.6522\n",
            "Epoch 17/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6327 - accuracy: 0.6452\n",
            "Epoch 18/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6299 - accuracy: 0.6498\n",
            "Epoch 19/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6294 - accuracy: 0.6512\n",
            "Epoch 20/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6306 - accuracy: 0.6493\n",
            "Epoch 21/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6305 - accuracy: 0.6503\n",
            "Epoch 22/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6291 - accuracy: 0.6492\n",
            "Epoch 23/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6286 - accuracy: 0.6506\n",
            "Epoch 24/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6302 - accuracy: 0.6509\n",
            "Epoch 25/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6304 - accuracy: 0.6510\n",
            "Epoch 26/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6287 - accuracy: 0.6495\n",
            "Epoch 27/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6317 - accuracy: 0.6480\n",
            "Epoch 28/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6340 - accuracy: 0.6473\n",
            "Epoch 29/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6294 - accuracy: 0.6480\n",
            "Epoch 30/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6310 - accuracy: 0.6497\n",
            "Epoch 31/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6354 - accuracy: 0.6417\n",
            "Epoch 32/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6320 - accuracy: 0.6487\n",
            "Epoch 33/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6531\n",
            "Epoch 34/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6331 - accuracy: 0.6473\n",
            "Epoch 35/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6301 - accuracy: 0.6512\n",
            "Epoch 36/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6336 - accuracy: 0.6510\n",
            "Epoch 37/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6348 - accuracy: 0.6469\n",
            "Epoch 38/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6293 - accuracy: 0.6508\n",
            "Epoch 39/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6294 - accuracy: 0.6525\n",
            "Epoch 40/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6502\n",
            "Epoch 41/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6503\n",
            "Epoch 42/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6312 - accuracy: 0.6487\n",
            "Epoch 43/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6336 - accuracy: 0.6512\n",
            "Epoch 44/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6311 - accuracy: 0.6513\n",
            "Epoch 45/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6352 - accuracy: 0.6462\n",
            "Epoch 46/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6305 - accuracy: 0.6543\n",
            "Epoch 47/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6289 - accuracy: 0.6539\n",
            "Epoch 48/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6516\n",
            "Epoch 49/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6332 - accuracy: 0.6495\n",
            "Epoch 50/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6292 - accuracy: 0.6530\n",
            "Epoch 51/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6291 - accuracy: 0.6550\n",
            "Epoch 52/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6327 - accuracy: 0.6498\n",
            "Epoch 53/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6298 - accuracy: 0.6516\n",
            "Epoch 54/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6301 - accuracy: 0.6509\n",
            "Epoch 55/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6330 - accuracy: 0.6489\n",
            "Epoch 56/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6310 - accuracy: 0.6494\n",
            "Epoch 57/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6323 - accuracy: 0.6508\n",
            "Epoch 58/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6321 - accuracy: 0.6521\n",
            "Epoch 59/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6523\n",
            "Epoch 60/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6325 - accuracy: 0.6481\n",
            "Epoch 61/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6314 - accuracy: 0.6488\n",
            "Epoch 62/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6315 - accuracy: 0.6493\n",
            "Epoch 63/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6483\n",
            "Epoch 64/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6322 - accuracy: 0.6495\n",
            "Epoch 65/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6507\n",
            "Epoch 66/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6315 - accuracy: 0.6514\n",
            "Epoch 67/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6296 - accuracy: 0.6531\n",
            "Epoch 68/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6301 - accuracy: 0.6519\n",
            "Epoch 69/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6295 - accuracy: 0.6535\n",
            "Epoch 70/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6335 - accuracy: 0.6495\n",
            "Epoch 71/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6332 - accuracy: 0.6483\n",
            "Epoch 72/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6275 - accuracy: 0.6519\n",
            "Epoch 73/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6284 - accuracy: 0.6549\n",
            "Epoch 74/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6291 - accuracy: 0.6528\n",
            "Epoch 75/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6290 - accuracy: 0.6509\n",
            "Epoch 76/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6325 - accuracy: 0.6504\n",
            "Epoch 77/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6498\n",
            "Epoch 78/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6317 - accuracy: 0.6526\n",
            "Epoch 79/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6271 - accuracy: 0.6556\n",
            "Epoch 80/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6331 - accuracy: 0.6471\n",
            "Epoch 81/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6354 - accuracy: 0.6493\n",
            "Epoch 82/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6354 - accuracy: 0.6446\n",
            "Epoch 83/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6299 - accuracy: 0.6504\n",
            "Epoch 84/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6309 - accuracy: 0.6505\n",
            "Epoch 85/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6483\n",
            "Epoch 86/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6507\n",
            "Epoch 87/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6303 - accuracy: 0.6493\n",
            "Epoch 88/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6297 - accuracy: 0.6507\n",
            "Epoch 89/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6489\n",
            "Epoch 90/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6320 - accuracy: 0.6492\n",
            "Epoch 91/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6271 - accuracy: 0.6556\n",
            "Epoch 92/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6301 - accuracy: 0.6490\n",
            "Epoch 93/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6302 - accuracy: 0.6477\n",
            "Epoch 94/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6316 - accuracy: 0.6490\n",
            "Epoch 95/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6339 - accuracy: 0.6474\n",
            "Epoch 96/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6284 - accuracy: 0.6530\n",
            "Epoch 97/500\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.6307 - accuracy: 0.6485\n",
            "Epoch 98/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6302 - accuracy: 0.6505\n",
            "Epoch 99/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6298 - accuracy: 0.6522\n",
            "Epoch 100/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6293 - accuracy: 0.6515\n",
            "Epoch 101/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6308 - accuracy: 0.6518\n",
            "Epoch 102/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6490\n",
            "Epoch 103/500\n",
            "804/804 [==============================] - 11s 14ms/step - loss: 0.6305 - accuracy: 0.6509\n",
            "Epoch 104/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6261 - accuracy: 0.6548\n",
            "Epoch 105/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6505\n",
            "Epoch 106/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6308 - accuracy: 0.6510\n",
            "Epoch 107/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6533\n",
            "Epoch 108/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6318 - accuracy: 0.6480\n",
            "Epoch 109/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6382 - accuracy: 0.6417\n",
            "Epoch 110/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6343 - accuracy: 0.6410\n",
            "Epoch 111/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6328 - accuracy: 0.6453\n",
            "Epoch 112/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6341 - accuracy: 0.6412\n",
            "Epoch 113/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6369 - accuracy: 0.6426\n",
            "Epoch 114/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6333 - accuracy: 0.6440\n",
            "Epoch 115/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6291 - accuracy: 0.6511\n",
            "Epoch 116/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6312 - accuracy: 0.6513\n",
            "Epoch 117/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6333 - accuracy: 0.6504\n",
            "Epoch 118/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6300 - accuracy: 0.6506\n",
            "Epoch 119/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6322 - accuracy: 0.6485\n",
            "Epoch 120/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6328 - accuracy: 0.6469\n",
            "Epoch 121/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6331 - accuracy: 0.6469\n",
            "Epoch 122/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6471\n",
            "Epoch 123/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6336 - accuracy: 0.6411\n",
            "Epoch 124/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6327 - accuracy: 0.6440\n",
            "Epoch 125/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6479\n",
            "Epoch 126/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6497\n",
            "Epoch 127/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6325 - accuracy: 0.6473\n",
            "Epoch 128/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6358 - accuracy: 0.6495\n",
            "Epoch 129/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6305 - accuracy: 0.6547\n",
            "Epoch 130/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6526\n",
            "Epoch 131/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6291 - accuracy: 0.6546\n",
            "Epoch 132/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6307 - accuracy: 0.6524\n",
            "Epoch 133/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6337 - accuracy: 0.6501\n",
            "Epoch 134/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6325 - accuracy: 0.6499\n",
            "Epoch 135/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6282 - accuracy: 0.6538\n",
            "Epoch 136/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6320 - accuracy: 0.6495\n",
            "Epoch 137/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6328 - accuracy: 0.6492\n",
            "Epoch 138/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6499\n",
            "Epoch 139/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6316 - accuracy: 0.6494\n",
            "Epoch 140/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6289 - accuracy: 0.6534\n",
            "Epoch 141/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6503\n",
            "Epoch 142/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6308 - accuracy: 0.6521\n",
            "Epoch 143/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6299 - accuracy: 0.6531\n",
            "Epoch 144/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6285 - accuracy: 0.6534\n",
            "Epoch 145/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6318 - accuracy: 0.6518\n",
            "Epoch 146/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6504\n",
            "Epoch 147/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6306 - accuracy: 0.6518\n",
            "Epoch 148/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6287 - accuracy: 0.6521\n",
            "Epoch 149/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6495\n",
            "Epoch 150/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6348 - accuracy: 0.6470\n",
            "Epoch 151/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6337 - accuracy: 0.6485\n",
            "Epoch 152/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6511\n",
            "Epoch 153/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6395 - accuracy: 0.6379\n",
            "Epoch 154/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6335 - accuracy: 0.6473\n",
            "Epoch 155/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6324 - accuracy: 0.6507\n",
            "Epoch 156/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6497\n",
            "Epoch 157/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6310 - accuracy: 0.6516\n",
            "Epoch 158/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6340 - accuracy: 0.6450\n",
            "Epoch 159/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6489\n",
            "Epoch 160/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6317 - accuracy: 0.6480\n",
            "Epoch 161/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6322 - accuracy: 0.6503\n",
            "Epoch 162/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6305 - accuracy: 0.6537\n",
            "Epoch 163/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6317 - accuracy: 0.6487\n",
            "Epoch 164/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6503\n",
            "Epoch 165/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6292 - accuracy: 0.6526\n",
            "Epoch 166/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6351 - accuracy: 0.6455\n",
            "Epoch 167/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6286 - accuracy: 0.6526\n",
            "Epoch 168/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6285 - accuracy: 0.6547\n",
            "Epoch 169/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6296 - accuracy: 0.6541\n",
            "Epoch 170/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6509\n",
            "Epoch 171/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6313 - accuracy: 0.6507\n",
            "Epoch 172/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6297 - accuracy: 0.6509\n",
            "Epoch 173/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6328 - accuracy: 0.6523\n",
            "Epoch 174/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6340 - accuracy: 0.6476\n",
            "Epoch 175/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6316 - accuracy: 0.6525\n",
            "Epoch 176/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6325 - accuracy: 0.6497\n",
            "Epoch 177/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6513\n",
            "Epoch 178/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6344 - accuracy: 0.6474\n",
            "Epoch 179/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6308 - accuracy: 0.6506\n",
            "Epoch 180/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6347 - accuracy: 0.6449\n",
            "Epoch 181/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6341 - accuracy: 0.6462\n",
            "Epoch 182/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6363 - accuracy: 0.6438\n",
            "Epoch 183/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6352 - accuracy: 0.6465\n",
            "Epoch 184/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6342 - accuracy: 0.6488\n",
            "Epoch 185/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6496\n",
            "Epoch 186/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6300 - accuracy: 0.6506\n",
            "Epoch 187/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6317 - accuracy: 0.6491\n",
            "Epoch 188/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6335 - accuracy: 0.6531\n",
            "Epoch 189/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6343 - accuracy: 0.6473\n",
            "Epoch 190/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6309 - accuracy: 0.6505\n",
            "Epoch 191/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6322 - accuracy: 0.6519\n",
            "Epoch 192/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6307 - accuracy: 0.6499\n",
            "Epoch 193/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6361 - accuracy: 0.6459\n",
            "Epoch 194/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6319 - accuracy: 0.6480\n",
            "Epoch 195/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6362 - accuracy: 0.6436\n",
            "Epoch 196/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6487\n",
            "Epoch 197/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6337 - accuracy: 0.6468\n",
            "Epoch 198/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6343 - accuracy: 0.6462\n",
            "Epoch 199/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6313 - accuracy: 0.6474\n",
            "Epoch 200/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6288 - accuracy: 0.6498\n",
            "Epoch 201/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6325 - accuracy: 0.6481\n",
            "Epoch 202/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6331 - accuracy: 0.6450\n",
            "Epoch 203/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6302 - accuracy: 0.6490\n",
            "Epoch 204/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6350 - accuracy: 0.6469\n",
            "Epoch 205/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6333 - accuracy: 0.6476\n",
            "Epoch 206/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6501\n",
            "Epoch 207/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6342 - accuracy: 0.6479\n",
            "Epoch 208/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6333 - accuracy: 0.6504\n",
            "Epoch 209/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6312 - accuracy: 0.6515\n",
            "Epoch 210/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6367 - accuracy: 0.6460\n",
            "Epoch 211/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6329 - accuracy: 0.6476\n",
            "Epoch 212/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6330 - accuracy: 0.6473\n",
            "Epoch 213/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6287 - accuracy: 0.6540\n",
            "Epoch 214/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6314 - accuracy: 0.6521\n",
            "Epoch 215/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6303 - accuracy: 0.6517\n",
            "Epoch 216/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6295 - accuracy: 0.6506\n",
            "Epoch 217/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6329 - accuracy: 0.6498\n",
            "Epoch 218/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6510\n",
            "Epoch 219/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6308 - accuracy: 0.6532\n",
            "Epoch 220/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6499\n",
            "Epoch 221/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6301 - accuracy: 0.6525\n",
            "Epoch 222/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6312 - accuracy: 0.6513\n",
            "Epoch 223/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6322 - accuracy: 0.6494\n",
            "Epoch 224/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6347 - accuracy: 0.6467\n",
            "Epoch 225/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6338 - accuracy: 0.6496\n",
            "Epoch 226/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6297 - accuracy: 0.6508\n",
            "Epoch 227/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6338 - accuracy: 0.6465\n",
            "Epoch 228/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6296 - accuracy: 0.6497\n",
            "Epoch 229/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6292 - accuracy: 0.6520\n",
            "Epoch 230/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6331 - accuracy: 0.6487\n",
            "Epoch 231/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6336 - accuracy: 0.6474\n",
            "Epoch 232/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6330 - accuracy: 0.6488\n",
            "Epoch 233/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6291 - accuracy: 0.6519\n",
            "Epoch 234/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6491\n",
            "Epoch 235/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6302 - accuracy: 0.6501\n",
            "Epoch 236/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6495\n",
            "Epoch 237/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6484\n",
            "Epoch 238/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6331 - accuracy: 0.6478\n",
            "Epoch 239/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6329 - accuracy: 0.6445\n",
            "Epoch 240/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6496\n",
            "Epoch 241/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6513\n",
            "Epoch 242/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6351 - accuracy: 0.6440\n",
            "Epoch 243/500\n",
            "804/804 [==============================] - 8s 11ms/step - loss: 0.6323 - accuracy: 0.6465\n",
            "Epoch 244/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6485\n",
            "Epoch 245/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6332 - accuracy: 0.6457\n",
            "Epoch 246/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6479\n",
            "Epoch 247/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6333 - accuracy: 0.6441\n",
            "Epoch 248/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6346 - accuracy: 0.6482\n",
            "Epoch 249/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6341 - accuracy: 0.6445\n",
            "Epoch 250/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6323 - accuracy: 0.6502\n",
            "Epoch 251/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6318 - accuracy: 0.6508\n",
            "Epoch 252/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6303 - accuracy: 0.6536\n",
            "Epoch 253/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6339 - accuracy: 0.6469\n",
            "Epoch 254/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6271 - accuracy: 0.6542\n",
            "Epoch 255/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6323 - accuracy: 0.6525\n",
            "Epoch 256/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6511\n",
            "Epoch 257/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6345 - accuracy: 0.6477\n",
            "Epoch 258/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6374 - accuracy: 0.6447\n",
            "Epoch 259/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6341 - accuracy: 0.6461\n",
            "Epoch 260/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6342 - accuracy: 0.6443\n",
            "Epoch 261/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6354 - accuracy: 0.6436\n",
            "Epoch 262/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6330 - accuracy: 0.6478\n",
            "Epoch 263/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6354 - accuracy: 0.6445\n",
            "Epoch 264/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6341 - accuracy: 0.6460\n",
            "Epoch 265/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6356 - accuracy: 0.6443\n",
            "Epoch 266/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6487\n",
            "Epoch 267/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6360 - accuracy: 0.6452\n",
            "Epoch 268/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6288 - accuracy: 0.6506\n",
            "Epoch 269/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6341 - accuracy: 0.6486\n",
            "Epoch 270/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6352 - accuracy: 0.6489\n",
            "Epoch 271/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6326 - accuracy: 0.6467\n",
            "Epoch 272/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6379 - accuracy: 0.6397\n",
            "Epoch 273/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6344 - accuracy: 0.6469\n",
            "Epoch 274/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6384 - accuracy: 0.6421\n",
            "Epoch 275/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6363 - accuracy: 0.6417\n",
            "Epoch 276/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6373 - accuracy: 0.6420\n",
            "Epoch 277/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6356 - accuracy: 0.6470\n",
            "Epoch 278/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6351 - accuracy: 0.6434\n",
            "Epoch 279/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6346 - accuracy: 0.6429\n",
            "Epoch 280/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6355 - accuracy: 0.6422\n",
            "Epoch 281/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6364 - accuracy: 0.6462\n",
            "Epoch 282/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6366 - accuracy: 0.6438\n",
            "Epoch 283/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6348 - accuracy: 0.6470\n",
            "Epoch 284/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6356 - accuracy: 0.6437\n",
            "Epoch 285/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6384 - accuracy: 0.6384\n",
            "Epoch 286/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6431 - accuracy: 0.6309\n",
            "Epoch 287/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6431 - accuracy: 0.6332\n",
            "Epoch 288/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6459 - accuracy: 0.6293\n",
            "Epoch 289/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6408 - accuracy: 0.6342\n",
            "Epoch 290/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6399 - accuracy: 0.6378\n",
            "Epoch 291/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6363 - accuracy: 0.6398\n",
            "Epoch 292/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6361 - accuracy: 0.6445\n",
            "Epoch 293/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6322 - accuracy: 0.6490\n",
            "Epoch 294/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6328 - accuracy: 0.6494\n",
            "Epoch 295/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6283 - accuracy: 0.6534\n",
            "Epoch 296/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6302 - accuracy: 0.6504\n",
            "Epoch 297/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6474\n",
            "Epoch 298/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6312 - accuracy: 0.6480\n",
            "Epoch 299/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6291 - accuracy: 0.6541\n",
            "Epoch 300/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6522\n",
            "Epoch 301/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6299 - accuracy: 0.6527\n",
            "Epoch 302/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6301 - accuracy: 0.6503\n",
            "Epoch 303/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6299 - accuracy: 0.6531\n",
            "Epoch 304/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6305 - accuracy: 0.6489\n",
            "Epoch 305/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6309 - accuracy: 0.6501\n",
            "Epoch 306/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6286 - accuracy: 0.6528\n",
            "Epoch 307/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6317 - accuracy: 0.6470\n",
            "Epoch 308/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6371 - accuracy: 0.6496\n",
            "Epoch 309/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6330 - accuracy: 0.6481\n",
            "Epoch 310/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6490\n",
            "Epoch 311/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6313 - accuracy: 0.6504\n",
            "Epoch 312/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6306 - accuracy: 0.6482\n",
            "Epoch 313/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6307 - accuracy: 0.6503\n",
            "Epoch 314/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6315 - accuracy: 0.6510\n",
            "Epoch 315/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6387 - accuracy: 0.6502\n",
            "Epoch 316/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6318 - accuracy: 0.6490\n",
            "Epoch 317/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6304 - accuracy: 0.6506\n",
            "Epoch 318/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6326 - accuracy: 0.6509\n",
            "Epoch 319/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6335 - accuracy: 0.6440\n",
            "Epoch 320/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6295 - accuracy: 0.6506\n",
            "Epoch 321/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6334 - accuracy: 0.6466\n",
            "Epoch 322/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6300 - accuracy: 0.6509\n",
            "Epoch 323/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6472\n",
            "Epoch 324/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6332 - accuracy: 0.6501\n",
            "Epoch 325/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6363 - accuracy: 0.6464\n",
            "Epoch 326/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6337 - accuracy: 0.6408\n",
            "Epoch 327/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6376 - accuracy: 0.6352\n",
            "Epoch 328/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6367 - accuracy: 0.6410\n",
            "Epoch 329/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6311 - accuracy: 0.6509\n",
            "Epoch 330/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6328 - accuracy: 0.6472\n",
            "Epoch 331/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6349 - accuracy: 0.6451\n",
            "Epoch 332/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6338 - accuracy: 0.6464\n",
            "Epoch 333/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6339 - accuracy: 0.6466\n",
            "Epoch 334/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6332 - accuracy: 0.6455\n",
            "Epoch 335/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6363 - accuracy: 0.6479\n",
            "Epoch 336/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6315 - accuracy: 0.6469\n",
            "Epoch 337/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6310 - accuracy: 0.6502\n",
            "Epoch 338/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6308 - accuracy: 0.6482\n",
            "Epoch 339/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6288 - accuracy: 0.6498\n",
            "Epoch 340/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6313 - accuracy: 0.6473\n",
            "Epoch 341/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6299 - accuracy: 0.6503\n",
            "Epoch 342/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6484\n",
            "Epoch 343/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6304 - accuracy: 0.6529\n",
            "Epoch 344/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6332 - accuracy: 0.6467\n",
            "Epoch 345/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6315 - accuracy: 0.6492\n",
            "Epoch 346/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6520\n",
            "Epoch 347/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6289 - accuracy: 0.6504\n",
            "Epoch 348/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6296 - accuracy: 0.6519\n",
            "Epoch 349/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6301 - accuracy: 0.6504\n",
            "Epoch 350/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6473\n",
            "Epoch 351/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6290 - accuracy: 0.6522\n",
            "Epoch 352/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6480\n",
            "Epoch 353/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6487\n",
            "Epoch 354/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6480\n",
            "Epoch 355/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6346 - accuracy: 0.6456\n",
            "Epoch 356/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6366 - accuracy: 0.6445\n",
            "Epoch 357/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6489\n",
            "Epoch 358/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6315 - accuracy: 0.6494\n",
            "Epoch 359/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6358 - accuracy: 0.6470\n",
            "Epoch 360/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6481\n",
            "Epoch 361/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6509\n",
            "Epoch 362/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6323 - accuracy: 0.6468\n",
            "Epoch 363/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6306 - accuracy: 0.6536\n",
            "Epoch 364/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6505\n",
            "Epoch 365/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6313 - accuracy: 0.6493\n",
            "Epoch 366/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6287 - accuracy: 0.6534\n",
            "Epoch 367/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6341 - accuracy: 0.6468\n",
            "Epoch 368/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6476\n",
            "Epoch 369/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6300 - accuracy: 0.6472\n",
            "Epoch 370/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6333 - accuracy: 0.6476\n",
            "Epoch 371/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6331 - accuracy: 0.6447\n",
            "Epoch 372/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6331 - accuracy: 0.6478\n",
            "Epoch 373/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6346 - accuracy: 0.6452\n",
            "Epoch 374/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6337 - accuracy: 0.6454\n",
            "Epoch 375/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6305 - accuracy: 0.6541\n",
            "Epoch 376/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6329 - accuracy: 0.6489\n",
            "Epoch 377/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6485\n",
            "Epoch 378/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6469\n",
            "Epoch 379/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6318 - accuracy: 0.6479\n",
            "Epoch 380/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6384 - accuracy: 0.6416\n",
            "Epoch 381/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6338 - accuracy: 0.6505\n",
            "Epoch 382/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6317 - accuracy: 0.6493\n",
            "Epoch 383/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6476\n",
            "Epoch 384/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6351 - accuracy: 0.6458\n",
            "Epoch 385/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6353 - accuracy: 0.6448\n",
            "Epoch 386/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6307 - accuracy: 0.6511\n",
            "Epoch 387/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6319 - accuracy: 0.6463\n",
            "Epoch 388/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6310 - accuracy: 0.6478\n",
            "Epoch 389/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6474\n",
            "Epoch 390/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6333 - accuracy: 0.6466\n",
            "Epoch 391/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6313 - accuracy: 0.6468\n",
            "Epoch 392/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6334 - accuracy: 0.6464\n",
            "Epoch 393/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6351 - accuracy: 0.6485\n",
            "Epoch 394/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6377 - accuracy: 0.6423\n",
            "Epoch 395/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6469\n",
            "Epoch 396/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6329 - accuracy: 0.6452\n",
            "Epoch 397/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6335 - accuracy: 0.6454\n",
            "Epoch 398/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6325 - accuracy: 0.6503\n",
            "Epoch 399/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6308 - accuracy: 0.6475\n",
            "Epoch 400/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6307 - accuracy: 0.6499\n",
            "Epoch 401/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6336 - accuracy: 0.6451\n",
            "Epoch 402/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6341 - accuracy: 0.6436\n",
            "Epoch 403/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6307 - accuracy: 0.6506\n",
            "Epoch 404/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6335 - accuracy: 0.6463\n",
            "Epoch 405/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6398 - accuracy: 0.6466\n",
            "Epoch 406/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6345 - accuracy: 0.6470\n",
            "Epoch 407/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6333 - accuracy: 0.6480\n",
            "Epoch 408/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6334 - accuracy: 0.6455\n",
            "Epoch 409/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6509 - accuracy: 0.6440\n",
            "Epoch 410/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6393 - accuracy: 0.6398\n",
            "Epoch 411/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6388 - accuracy: 0.6399\n",
            "Epoch 412/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6350 - accuracy: 0.6398\n",
            "Epoch 413/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6352 - accuracy: 0.6422\n",
            "Epoch 414/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6391 - accuracy: 0.6400\n",
            "Epoch 415/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6369 - accuracy: 0.6405\n",
            "Epoch 416/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6360 - accuracy: 0.6422\n",
            "Epoch 417/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6459\n",
            "Epoch 418/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6346 - accuracy: 0.6445\n",
            "Epoch 419/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6375 - accuracy: 0.6405\n",
            "Epoch 420/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6349 - accuracy: 0.6438\n",
            "Epoch 421/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6491\n",
            "Epoch 422/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6326 - accuracy: 0.6450\n",
            "Epoch 423/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6342 - accuracy: 0.6474\n",
            "Epoch 424/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6320 - accuracy: 0.6473\n",
            "Epoch 425/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6332 - accuracy: 0.6433\n",
            "Epoch 426/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6336 - accuracy: 0.6434\n",
            "Epoch 427/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6320 - accuracy: 0.6465\n",
            "Epoch 428/500\n",
            "804/804 [==============================] - 8s 11ms/step - loss: 0.6341 - accuracy: 0.6458\n",
            "Epoch 429/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6361 - accuracy: 0.6401\n",
            "Epoch 430/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6340 - accuracy: 0.6427\n",
            "Epoch 431/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6361 - accuracy: 0.6400\n",
            "Epoch 432/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6356 - accuracy: 0.6452\n",
            "Epoch 433/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6298 - accuracy: 0.6494\n",
            "Epoch 434/500\n",
            "804/804 [==============================] - 8s 11ms/step - loss: 0.6316 - accuracy: 0.6460\n",
            "Epoch 435/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6495\n",
            "Epoch 436/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6345 - accuracy: 0.6449\n",
            "Epoch 437/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6344 - accuracy: 0.6472\n",
            "Epoch 438/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6293 - accuracy: 0.6524\n",
            "Epoch 439/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6516\n",
            "Epoch 440/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6332 - accuracy: 0.6478\n",
            "Epoch 441/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6315 - accuracy: 0.6508\n",
            "Epoch 442/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6320 - accuracy: 0.6482\n",
            "Epoch 443/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6352 - accuracy: 0.6508\n",
            "Epoch 444/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6283 - accuracy: 0.6534\n",
            "Epoch 445/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6333 - accuracy: 0.6478\n",
            "Epoch 446/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6316 - accuracy: 0.6492\n",
            "Epoch 447/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6309 - accuracy: 0.6492\n",
            "Epoch 448/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6317 - accuracy: 0.6487\n",
            "Epoch 449/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6310 - accuracy: 0.6513\n",
            "Epoch 450/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6499\n",
            "Epoch 451/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6289 - accuracy: 0.6501\n",
            "Epoch 452/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6327 - accuracy: 0.6501\n",
            "Epoch 453/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6328 - accuracy: 0.6513\n",
            "Epoch 454/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6314 - accuracy: 0.6512\n",
            "Epoch 455/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6314 - accuracy: 0.6496\n",
            "Epoch 456/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6292 - accuracy: 0.6542\n",
            "Epoch 457/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6285 - accuracy: 0.6522\n",
            "Epoch 458/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6292 - accuracy: 0.6547\n",
            "Epoch 459/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6323 - accuracy: 0.6507\n",
            "Epoch 460/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6506\n",
            "Epoch 461/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6305 - accuracy: 0.6520\n",
            "Epoch 462/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6311 - accuracy: 0.6497\n",
            "Epoch 463/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6315 - accuracy: 0.6513\n",
            "Epoch 464/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6315 - accuracy: 0.6486\n",
            "Epoch 465/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6321 - accuracy: 0.6541\n",
            "Epoch 466/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6322 - accuracy: 0.6507\n",
            "Epoch 467/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6281 - accuracy: 0.6555\n",
            "Epoch 468/500\n",
            "804/804 [==============================] - 8s 11ms/step - loss: 0.6308 - accuracy: 0.6546\n",
            "Epoch 469/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6336 - accuracy: 0.6487\n",
            "Epoch 470/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6312 - accuracy: 0.6491\n",
            "Epoch 471/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6305 - accuracy: 0.6502\n",
            "Epoch 472/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6322 - accuracy: 0.6504\n",
            "Epoch 473/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6344 - accuracy: 0.6431\n",
            "Epoch 474/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6503\n",
            "Epoch 475/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6300 - accuracy: 0.6536\n",
            "Epoch 476/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6304 - accuracy: 0.6518\n",
            "Epoch 477/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6293 - accuracy: 0.6573\n",
            "Epoch 478/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6318 - accuracy: 0.6508\n",
            "Epoch 479/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6325 - accuracy: 0.6532\n",
            "Epoch 480/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6314 - accuracy: 0.6528\n",
            "Epoch 481/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6296 - accuracy: 0.6528\n",
            "Epoch 482/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6280 - accuracy: 0.6514\n",
            "Epoch 483/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6329 - accuracy: 0.6502\n",
            "Epoch 484/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6300 - accuracy: 0.6513\n",
            "Epoch 485/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6317 - accuracy: 0.6480\n",
            "Epoch 486/500\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.6329 - accuracy: 0.6477\n",
            "Epoch 487/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6347 - accuracy: 0.6468\n",
            "Epoch 488/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6312 - accuracy: 0.6499\n",
            "Epoch 489/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6307 - accuracy: 0.6526\n",
            "Epoch 490/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6302 - accuracy: 0.6504\n",
            "Epoch 491/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6324 - accuracy: 0.6505\n",
            "Epoch 492/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6487\n",
            "Epoch 493/500\n",
            "804/804 [==============================] - 9s 11ms/step - loss: 0.6314 - accuracy: 0.6494\n",
            "Epoch 494/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6336 - accuracy: 0.6507\n",
            "Epoch 495/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6303 - accuracy: 0.6487\n",
            "Epoch 496/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6283 - accuracy: 0.6545\n",
            "Epoch 497/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6319 - accuracy: 0.6499\n",
            "Epoch 498/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6285 - accuracy: 0.6515\n",
            "Epoch 499/500\n",
            "804/804 [==============================] - 8s 10ms/step - loss: 0.6325 - accuracy: 0.6506\n",
            "Epoch 500/500\n",
            "804/804 [==============================] - 8s 9ms/step - loss: 0.6327 - accuracy: 0.6478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the optimized model using the test data\n",
        "model_loss_optimized_3, model_accuracy_optimized_3 = nn_optimized_3.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Model Loss: {model_loss_optimized_3}, Optimized Model Accuracy: {model_accuracy_optimized_3}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-gTji13jiY6",
        "outputId": "af52b845-ba36-4ef8-87a4-f71b5e84d67e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.6084 - accuracy: 0.7245 - 641ms/epoch - 2ms/step\n",
            "Optimized Model Loss: 0.6083703637123108, Optimized Model Accuracy: 0.7245481014251709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the further optimized model to HDF5 file\n",
        "nn_optimized_3.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "id": "k1HC9Q1fd5gC"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}